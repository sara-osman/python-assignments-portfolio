{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124639b7-c147-4b2d-97d5-12c226b00c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Importing numpy for numerical computations\n",
    "import matplotlib.pyplot as plt  # Importing matplotlib for plotting\n",
    "from numpy.f2py.capi_maps import f2cexpr  # Unused import, you may want to remove this if not needed\n",
    "\n",
    "\n",
    "# definitions for the three example functions\n",
    "def f1(x):\n",
    "    \"\"\"Defines the first function: f(x) = x^2\"\"\"\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    \"\"\"Defines the second function: f(x) = x^4 - 2x^2\"\"\"\n",
    "    return x ** 4 - 2 * x ** 2\n",
    "\n",
    "\n",
    "def f3(x):\n",
    "    \"\"\"\n",
    "    Defines the third function: \n",
    "    - f(x) = x^x for x > 0\n",
    "    - f(x) = 1 for x = 0\n",
    "    - f(x) = |x|^|x| for x < 0\n",
    "    \"\"\"\n",
    "    if x > 0:\n",
    "        return x ** x\n",
    "    elif x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return abs(x) ** abs(x)\n",
    "\n",
    "\n",
    "# derivative function using approximation\n",
    "def dydx(f, x):\n",
    "    \"\"\"\n",
    "    Calculates the derivative of the function f at point x\n",
    "    using a central difference approximation.\n",
    "    \"\"\"\n",
    "    return (f(x + 10 ** -10) - f(x - 10 ** -10)) / (2 * 10 ** -10)\n",
    "\n",
    "\n",
    "# gradient descent method to find the minimum of a function\n",
    "def find_minimum(f, x0, learning_rate):\n",
    "    \"\"\"\n",
    "    Finds the minimum of a function f starting at x0 using gradient descent.\n",
    "    Parameters:\n",
    "        f: The function to minimize.\n",
    "        x0: Initial guess for the minimum.\n",
    "        learning_rate: Step size for gradient descent.\n",
    "    Returns:\n",
    "        A string with the coordinates of the minimum or an error message.\n",
    "    \"\"\"\n",
    "    x_coords = [x0]  # to store x-coordinates during optimization\n",
    "    y_coords = [f(x0)]  #to store corresponding y-coordinates\n",
    "\n",
    "    i = 0  # iteration counter\n",
    "\n",
    "    # iterate until maximum iterations or convergence criterion is met\n",
    "    while i <= 10 ** 3 and dydx(f, x_coords[i]) > 10 ** -10:\n",
    "        # Update x-coordinate using gradient descent formula\n",
    "        x_coords.append(x_coords[i] - learning_rate * dydx(f, x_coords[i]))\n",
    "        # Update y-coordinate\n",
    "        y_coords.append(f(x_coords[i]))\n",
    "        i += 1\n",
    "\n",
    "        # if maximum iterations are reached, return an error message\n",
    "        if i == 10 ** 3:\n",
    "            return \"Error! No minimum could be found. Try a different learning rate.\"\n",
    "\n",
    "    # plotting the function and the gradient descent steps\n",
    "    plot_range = np.linspace(min(x_coords) - 0.5, max(x_coords) + 0.5, 10000)  # Define plot range\n",
    "    function_range = [f(i) for i in plot_range]  # Evaluate function over the plot range\n",
    "    plt.plot(plot_range, function_range)  # Plot the function\n",
    "    plt.plot(x_coords, y_coords)  # Plot the gradient descent path\n",
    "    plt.title(\"Gradient Descent Steps\")  # Add a title to the plot\n",
    "    plt.xlabel(\"x\")  # Label the x-axis\n",
    "    plt.ylabel(\"f(x)\")  # Label the y-axis\n",
    "    plt.show()  # Display the plot\n",
    "\n",
    "    # return the coordinates of the minimum found\n",
    "    return \"Minimum of this function is at (\" + str(round(x_coords[i - 1], 3)) + \", \" + str(round(y_coords[i - 1], 3)) + \").\"\n",
    "\n",
    "\n",
    "# Main function to handle user input and perform optimization\n",
    "def main():\n",
    "    done = False  # Flag to control the loop\n",
    "\n",
    "    while not done:\n",
    "        # Prompt the user to select a function to minimize\n",
    "        function_name = input(\"Enter which function you want to minimize (1, 2, 3): \")\n",
    "\n",
    "        function = None  # Placeholder for the selected function\n",
    "\n",
    "        if function_name == \"1\":\n",
    "            function = f1\n",
    "        elif function_name == \"2\":\n",
    "            function = f2\n",
    "        elif function_name == \"3\":\n",
    "            function = f3\n",
    "        else:\n",
    "            print(\"Invalid input! Please choose 1, 2, or 3.\")\n",
    "            continue  # Restart the loop for invalid input\n",
    "\n",
    "        x0 = float(input(\"Enter a starting point for the optimization: \"))\n",
    "        learning_rate = float(input(\"Enter a learning rate for the optimization: \"))\n",
    "\n",
    "        print(find_minimum(function, x0, learning_rate))\n",
    "\n",
    "        continue_or_not = input(\"Would you like to continue (yes or no): \")\n",
    "\n",
    "    \n",
    "        if continue_or_not.lower() == \"no\":\n",
    "            done = True\n",
    "\n",
    "\n",
    "# Execute the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073211aa-49ba-4029-b306-e4eecb0d4e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
